{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TiagoFerreira-lab/-CNN-Convolutional-neural-network-/blob/main/Readme.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azlqqYM1Wgfz"
      },
      "source": [
        "# Image Classification with CNN\n",
        "\n",
        "Build a Convolutional Neural Network (CNN) model to classify images from a given dataset into predefined categories/classes.\n",
        "\n",
        "[Task Descriptions and Project Instructions](https://github.com/ironhack-labs/project-1-deep-learning-image-classification-with-cnn)\n",
        "\n",
        "\n",
        "## üìä Project Results\n",
        "In this project, we classified images from the animals 10 data set.\n",
        "- Pre-processed data\n",
        "- Built a sequential CNN model\n",
        "- Optimized the model\n",
        "- Prediction accuracy of: 81.63%\n",
        "\n",
        "---\n",
        "\n",
        "## üìÇ Repository Folders and Files\n",
        "\n",
        "Here is a short description of the folder and files available on the repository.\n",
        "\n",
        "\n",
        "### Documents\n",
        "- Presentation\n",
        "\n",
        "### Notebooks  \n",
        "- split_validation_set: split the data set to one set for training and testing (90%) and a second one to make predictions (10%)\n",
        "- model_1.ypynb : The starting point model\n",
        "- model_optimized_ypnb: The optimized model\n",
        "- test_images: folder of unseen images to test on the model\n",
        "\n",
        "---\n",
        "\n",
        "## üì¶ Required Modules and Dependencies\n",
        "\n",
        "The following modules are required for running this project:\n",
        "\n",
        "### üîπ **System & File Management**\n",
        "- `os` ‚Äì Handles file paths and directory operations.  \n",
        "- `zipfile` ‚Äì Extracts compressed datasets.  \n",
        "- `time` ‚Äì Measures execution time of processes.  \n",
        "- `google.colab.drive` ‚Äì Mounts Google Drive for dataset storage.  \n",
        "- `gdown` ‚Äì Downloads datasets from Google Drive.\n",
        "\n",
        "### üîπ **Data Preprocessing & Image Handling**\n",
        "- `tensorflow.keras.preprocessing.image` ‚Äì Loads, processes, and augments images.  \n",
        "- `ImageDataGenerator` ‚Äì Applies **data augmentation** to improve model generalization.  \n",
        "- `opencv` (`cv2`) ‚Äì (Optional) Handles advanced image processing.  \n",
        "- `numpy` ‚Äì Handles numerical operations for image arrays.  \n",
        "\n",
        "### üîπ **Deep Learning: TensorFlow & Keras**\n",
        "- `tensorflow` ‚Äì Provides the framework for CNN training and inference.  \n",
        "- `tensorflow.keras.models.Sequential` ‚Äì Defines a sequential CNN model.  \n",
        "- `tensorflow.keras.layers.Conv2D` ‚Äì Extracts features from images using convolutional layers.  \n",
        "- `tensorflow.keras.layers.MaxPooling2D` ‚Äì Reduces spatial dimensions while retaining key features.  \n",
        "- `tensorflow.keras.layers.Flatten` ‚Äì Converts feature maps into a **1D vector** for dense layers.  \n",
        "- `tensorflow.keras.layers.Dense` ‚Äì Fully connected layers for classification.  \n",
        "- `tensorflow.keras.layers.Dropout` ‚Äì Regularization technique to prevent **overfitting**.  \n",
        "- `tensorflow.keras.layers.BatchNormalization` ‚Äì Normalizes activations for **stable training**.  \n",
        "- `tensorflow.keras.regularizers.l2` ‚Äì Applies **L2 Regularization** to prevent **overfitting**.  \n",
        "\n",
        "### üîπ **Model Optimization & Callbacks**\n",
        "- `tensorflow.keras.callbacks.ReduceLROnPlateau` ‚Äì Adjusts the **learning rate** dynamically when training slows down.  \n",
        "- `tensorflow.keras.callbacks.EarlyStopping` ‚Äì Stops training when validation performance **stagnates**.  \n",
        "- `tensorflow.keras.optimizers.Adam` ‚Äì Adaptive **optimization algorithm** for faster convergence.  \n",
        "- `tensorflow.keras.backend as K` ‚Äì Provides **low-level functions** for manipulating tensors.  \n",
        "\n",
        "### üîπ **Model Evaluation & Metrics**\n",
        "- `sklearn.metrics.confusion_matrix` ‚Äì Computes the confusion matrix for model predictions.  \n",
        "- `sklearn.metrics.classification_report` ‚Äì Provides a summary of **precision, recall, and F1-score**.  \n",
        "- `sklearn.metrics.precision_score` ‚Äì Measures how many of the predicted positives are actually correct.  \n",
        "- `sklearn.metrics.recall_score` ‚Äì Evaluates how well the model identifies **true positives**.  \n",
        "- `sklearn.metrics.f1_score` ‚Äì Balances **precision and recall** into a single metric.  \n",
        "\n",
        "### üîπ **Data Visualization**\n",
        "- `matplotlib.pyplot` ‚Äì Plots **loss curves, accuracy trends, and sample images**.  \n",
        "- `seaborn` ‚Äì Creates **confusion matrix heatmaps** for visualizing model predictions.  \n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Installation\n",
        "Before running the project, ensure that all required dependencies are installed.\n",
        "\n",
        "### **üîπ Install Using `requirements.txt`**\n",
        "To install all necessary libraries at once, run:\n",
        "\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "\n",
        "### Additional Folders\n",
        "**test_images**: folder of unseen images to test on the model\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}